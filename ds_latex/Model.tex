\chapter{Problem formulation}

This chapter gives a short overview of the classical RMDP from \cite{UlmerRMDP} and the RMDPEAT introduced in \cite{Hildebrandt2020_EAT}. Then, we give a formal, but concise description of the EAT.
\section{Restaurant Meal Delivery Problem}

According to the taxonomy for dynamic vehicle routing problems introduced in \cite{psaraftis}, the classical RMDP belongs to the category of dynamic (1) and stochastic (2) problems since (1) drivers routes need to be reoptimized over time by means of a routing policy and (2) only the probability distributions of inputs are known at the start of the problem respectively. In the RMDP, customers are distributed across a known service area and request service during a finite service time window. Drivers are distributed in the service area and dispatched by the meal delivery platform that provides meal delivery service for participating restaurants. 

The RMDP process is triggered with the arrival of customer requests. When a customer requests service on the platform of the meal delivery service, the assignment policy proposed in \cite{UlmerRMDP} assigns the customer an available driver. When this is done, the dispatcher updates the routes of drivers. It is therefore assumed that the routing policy is exogenously given. The assigned driver then drives to the restaurant, picks the meal up and eventually waits at the restaurant if meals are not ready yet, and then delivers it to the customer. This whole process is impacted by uncertainty in the arrival of customer requests, pick-up and delivery times of drivers, and meal preparation times of restaurants.
The RMDP allows order bundling. Order bundling refers to the possibility of assigning a vehicle more than one order at a time which results in greater flexibility for assignment decisions. In addition, to potentially bundle orders better, the RMDP allows for postponement in order assignment.
Overall, the RMDP seeks maximization in the amount of served customers and minimization in delivery delays. 

\cite{UlmerRMDP} formulated the RMDP formally by means of the route-based markov decision process (MDP) notation introduced in \cite{ulmer2017route}, which will aid in understanding fundamental differences between the RMDPEAT and the classical RMDP. For the full formulation of the RMDP as a route-based MDP, the reader is referred to \cite{UlmerBarrett2017_TWAP}. We begin by describing basic terminology in route-based MDP notation for the RMDP:
\begin{description}[font=$\bullet$\scshape\bfseries]
	\item \textbf{Decision epochs}: A decision epoch $ k $ is a point of time which triggers a decision $ x $. In the RMDP, decision epochs occur when a customer requests delivery or an order gets postponed since orders must be assigned and drivers routes must be updated in both cases.
	
	\item \textbf{Decision states}: Decision states contain any informations needed to make a decision at their corresponding decision epoch. In the RMDP, a decision state $ S_k $ contains the set of requested orders $ \mathcal{D}_k $ including the new order $ D_k $, and the set of planned routes $ \Theta_k $ at decision epoch $ k $. With planned routes, the RMDP refers to potential routing decisions that can be made when a new decision is made. 
	
	\item \textbf{Decisions and deterministic costs}: A decision in the RMDP is the assignment of unassigned orders to vehicles at the corresponding decision epoch. This leads to a transition from the pre-decision state to the post-decision state $ S^{x}_k $. $ S^{x}_k $ is the consequence of a decision point being triggered and represents the state with new, updated planned routes $ \Theta_k $. Note that in post-decision state $ S^{x}_k $, the decision still has to be carried out and hence is still not realized. Since planned arrival times are known, \cite{UlmerBarrett2017_TWAP} define the deterministic costs as the marginal change indelay, which in turn is the difference of currently planend delay for routes $ \Theta_k $ at decision epoch $ k $ and updated planned delays for updated routes $ \Theta^{x}_k $ associated with the post-decision state $ S^{x}_k $ as deterministic costs.
	
	\item \textbf{Transitions and Stochastic Costs}: A transition to the next decision epoch $ k+1 $  with the next pre-decision state $ S_{k+1} = (S_k, x, \omega) $ is induced when the decision $ x $ following state $ S_k $ is realized. $ \omega $ denotes exogenous, random information that is realized during the transition from post-decision state $ S^{k}_x $ to the next pre-decision state $ S_{k+1} $ and is finally known when the subsequent decision epoch $ k+1 $ is triggered. In the RMDP, realized random information is considered as uncertain delivery times impacted by uncertainty in meal preparation times. Given the planned arrival times of the updated planned routes $ \Theta^{x}_k $ in post-decision state $ S^{x}_k $ and the actual arrival times resulting from a realization of $ \omega $, \cite{UlmerBarrett2017_TWAP} define the stochastic costs as the realized delay over all customers served during the transition from $ k $ to $ k+1 $.
\end{description}

Now that we are familiar with the route-based MDP notation for the RMDP, we will point out how the RMDPEAT differs from the classical RMDP in the subsequent section. 
\section{Restaurant Meal Delivery Problem with Arrival Time Estimation}

When a request comes in, a new decision point in the RMDP is triggered. Consequently, an assignment decision has to be made. After that, the RMDP assigns the request to the driver regarded as the optimal choice wrt. deterministic and stochastic costs. When this is done, the random information occuring during the transition is realized when the next decision epoch $ k+1 $ is triggered. However, customers' restaurant choices are not modeled in the RMDP process since random information in the RMDP only includes uncertainty in meal preparation and delivery. The RMDPEAT however additionally considers the customer's restaurant choice as random information and models it explicitly by assuming that customer preferences are composed of customers' static restaurant and dynamic arrival time preferences. Hence, the RMDPEAT accounts for the customer order process. 

The RMDPEAT process is triggered when a customer requests delivery. This leads to the calculation of estimated times of arrival for each restaurant the customer can order from that are then communicated to the customer. Based on his restaurant and arrival time preferences, the customer decides either to order from a restaurant or to not order at all. When the customer decides not to order, the process is terminated. When the customer orders, the dispatcher informs the chosen restaurant and updates driver routes. The process terminates when the request has been served. 
\cite{UlmerBarrett2017_TWAP} assume that planned arrival times are assumptions made by the dispatcher, whereas \cite{Hildebrandt2020_EAT} explicitly account for the arrival time estimations communicated to the customer. As we already pointed out in chapter 1 of this paper, this is crucial as there is evidence of arrival delay having a negative impact on customer satisfaction.

The changes wrt. to the route-based MDP are the following:
\begin{description}[font=$\bullet$\scshape\bfseries]
	\item \textbf{Modified Decision States}: As described, the RMDP state space contains the set of orders that are yet to serve, and the set of planned routes. Additionally, the RMDPEAT state space is extended by the set of restaurants $ R_k $ and their respective workloads. Further, they extend the information available for routes by not only including sequences of pick up and delivery locations to be visited, which is just spatial information, but also incorporating temporal quantities for each sequences as well. 
	\item \textbf{Modified Decisions}: 
	In the RMDP, a decision is triggered if a customer requests service or if the assignment of a request is postponed. However, decisions made in the RMDPEAT have two stages. As in the RMDP, the first stage updates the set of orders and the driver routes. The RMDPEAT adds a second stage where arrival times are estimated based on the current RMDPEAT state and the route updates. These estimations are then communicated to the customer.  
	\item \textbf{Modified Transitions}: In the RMDPEAT, the restaurant choice of the customer and stochastic parking and meal preparation times of the delivery actions happening during a transition are now additionally considered as random information. Therefore, when decision epoch $ k $ is triggered and the transition to epoch $ k+1 $ is therefore finished, the random information realized during transition is known. 
\end{description}

Since the RMDPEAT is a composite of two problems, namely the RMDP which accounts for driver assignment and routing, and the problem of estimating arrival times for delivery routing (EAT), it seeks to maximize the expected number of served customers and communicate accurate arrival times to the customer. The latter is the focus of the EAT, which is covered in the next section in detail.

\section{Estimating arrival times for delivery routing}

\cite{Hildebrandt2020_EAT} define the RMDPEAT as a dynamic decision process. Based on that, they further formulate the problem of estimating arrival times for delivery routing (EAT), which is just the EAT part of the RMDPEAT process, formally and in detail as well. In the following, we recap their EAT formulation formally since we operate on the same underlying DVR problem setting and share a the same task in predicting arrival times, but keep our explanations concise. For a in-depth explanation of the EAT, the interested reader is referred to section 3.2 in \cite{Hildebrandt2020_EAT}. 

Let $ c_k $ denote the k-th customer requesting service at time point $ t_k $, $ \mathcal{N}_k $ the set of customers that have requested service but have not been served yet, $ R_k $ the set of restaurants, and $ \Theta_k $ the set of planned routes for each driver at decision epoch $ k $. The decision state for the RMDPEAT is therefore given as $ S_k = (t_k, \mathcal{N}_k \cup c_k, \mathcal{R}_k, \Theta_k) $. Decisions are triggered when customers request service and happen in two stages: First, potential routing decisions $ \Theta_{ik} $ for every restaurant $ i = 1, \dots, |\mathcal{R}_k| $ the customer can order from are computed. The union of the RMDPEAT state $ S_k $ with these potential routing decisions $ \Theta_{ik} $ represents the EAT state $ S^{EAT}_k := (S_k \cup \Theta_{ik})$. Based on $ S^{EAT}_k $, we estimate arrival times for each potential routes $ \Theta_{ik} $ respectively and denote them as $ X(S^{EAT}_k) := (X_{ik})_{i = 1, \dots, |\mathcal{R}_k|}$. Customers then choose a prefered restaurant based on their individual preference functions $ \Phi_k((X_{ik})_{i \in \{1,\dots, R_k\}}) $.  
The objective of the EAT is defined as
\begin{equation}\label{equation:3.1}
	\min_{X(S^{EAT}_k)(j) \in \mathbb{R}_+} 
	\mathbb{E}_{S^{EAT}_{k}} 
	(|| A(S^{EAT}_{k})(j) - X(S^{EAT}_{k})(j)||^{2}_{2}).
\end{equation}
Equation \ref{equation:3.1} seeks to minimize the expected deviance of the estimated arrival time $ X(S^{EAT}_{k})(j) $ from the actual arrival time $ A(S^{EAT}_{k})(j) $ where $ j $ represents the restau-rant that the customer will chose. The deviance is measured with the mean squared error.

    