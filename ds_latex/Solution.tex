\chapter{Methodology}
This chapter presents the solution approach.
Section 4.1 motivates our problem. 
Section 4.2 gives and introduction to supervised learning and presents the algorithms considered in the comparison in detail.
Section 4.3 is about the different feature selection techniques applied in the computational study. 
Section 4.4 defines the process by which we evaluate the algorithms in order to assess the quality of each algorithm.

\section{Motivation}

- Why machine learning --> Why offline supervised learning --> Why Tree-Based ensembles and NNs
- Why bother comparing them


\section{Algorithms}

This section shortly introduces the statistical framework of supervised learning and then proceeds with the detailed examination of how each algorithm included in our comparison works.  

As inputs, supervised learning algorithms receive \textbf{training data} in form of a finite set $ S = \{({x}_{2}, y_2), ({x}_{2}, y_2), \dots, ({x}_{n}, y_n)\}$ of N pairs from $ \mathcal{X} \times \mathcal{Y} $ where $ x_i $ is an \textbf{sample} associated to it's corresponding \textbf{label} $ y_i $.
They return a \textbf{hypothesis} $ h: \mathcal{X} \to \mathcal{Y} $ that aims to predict the corresponding label $ y \in Y $ for any $ x \in X $, but especially for $ x \notin S $.
We further assume a joint probability distribution $ P $ over $ \mathcal{X} $ and $ \mathcal{Y} $ each pair is identically and independently distributed according to. 
This assumption allows us to take uncertainties of predictions into account.
Thus, $ h(x) $ can be treated as a random variable being conditionally distributed with $ P(y | x) $ for a given $ x $, not as a deterministic function of $ x $.
The prediction accuracy of $ h $ is measured with a  \textbf{loss function} $ L : Y \times Y \to \mathbb{R}^{\geq 0}$.
For a given pair $ ({x}_i, y_i) $, the loss function $ L(y_i, \hat{y}_i) $ represents the deviance of a predicted label $ \hat{y_i} $ from the actual corresponding label $ y_i $ of $ x_i $. 
The average loss across all $ x \in S $ is called \textbf{empirical risk} associated with the hypothesis.
Thus, the goal of a supervised learning algorithm is to find the optimal hypothesis $ h^* $ for which the overall empirical risk is minimal: 
\begin{equation}
	h^* = \argmin_{h \in H} \dfrac{1}{n} \sum_{i=1}^{n} L(h(x_i), y_i)
\end{equation}

Predictions can generally be made for either a \textbf{regression} or \textbf{classification} problem which differ in the nature of their target variable. 
While regression is used to predict continuous targets $ Y = \mathbb{R} $, classification predicts discrete $ Y $. The arrival time estimation problem is a regression task since we are estimating (continuous) arrival times.
Although various supervised learning models use different mathematical procedures to predict targets, all of them follow the principle of induction, meaning that general rules are inductively inferred from training data. This is also called \textbf{generalization}.  
In order for a model to generalize well, two phenomena have to be avoided: \textbf{Underfitting} and \textbf{Overfitting}. 
Poor predictions on both the training and test data indicate that a model is underfitted, whereas an overfitted model is characterized by very good prediction accuracy on the training data, but poor accuracy on test data. 
In supervised learning, this is known as the \textbf{bias-variance tradeoff}. 
A overfitted model is low in bias and high in variance, whereas the same goes vice versa for underfitted models. 
The key challenge therefore lies in discovering a model that is ideally low in bias and low in variance and thus has good prediction accuracy especially on test data.
 
\subsection{Linear Models}

\subsection{Tree-based ensembles}

As shown in the literature review, tree-based ensembles like GBDTs and Random Forests are popular in the field of arrival time estimation. Behind ensemble learning lies the idea that combinations or \textit{ensembles} of many so called \textit{base learners}, form an accurate prediction model.  

A single decision tree is given by
\begin{equation}
h(x) = \sum_{m=1}^{M} c_m I(x \in R_m)
\end{equation}









The first step in GBDT is to initialize a model by taking the derivate of the loss function with a known target $ y_i $ and an unknown target prediction $ \gamma $ that is constant for all corresponding $ y_i $.
\begin{equation}
h_{0}(x) =  \argmin_{\gamma} \sum_{i=1}^n L(y_i,\gamma) \label{gbdt_step1}
\end{equation}
Given the initial model $ h_0(x) $, M regression trees can now be build sequentially as shown in the following. 
The first step computes pseudo-residuals $ r_{im} $ between the prediction value of the former learner for the i-th sample $ h_{m-1}(x) $ and the actual i-th target for the m-th tree $ y_i $by deriving the loss function w.r.t to $ h_{m-1}(x) $: 
\begin{equation}
	r_{im}\ = - \bigg[\dfrac{\delta L(y_i, h(x_i))}{\delta h(x_i)}\bigg]_{h(x) = h_{m-1}(x)}
\end{equation} 
for every i-th example.

In the second step, the algorithm fits a regression tree to every $ r_{im} $ and creates disjoint regions $ R_{jm} $ for $j = 1, ..., J_m$. 

In the third step, we compute: 
\begin{equation}
	\gamma_{jm} = \argmin_{\gamma} \sum_{x_i \in R_{ij}} L(y_i, h_{m-1}(x_i) + \gamma)
\end{equation}
for every terminal region j in the m-th tree. 
Given this, we now update the former weak learner with the new one:
\begin{equation}
	h_m(x) = h_{m-1}(x) + \alpha \sum_{j=1}^{J_m} \gamma_{m}I(x \in R_{jm})
\end{equation}
where $ \alpha $ is the learning rate, and $ I(\cdot) $ is the indicator function.

\subsection{Neural Networks}

\section{Feature Selection}

As shown, researchers used different feature selection methods. A majority of the presented papers crafted their features manually relying on their domain expertise, whereas others (e.g \cite{Siripanpornchana2016_AnnWithDbnFS} and \cite{Huang2018_GBDT}) used representation learning techniques.


- Raw Data 
- Manual feature selection
- Feature learning via deep autoencoder

\section{Evaluation} 
- Use MSE, MAE, MAPE etc. to derive infos about accuracy
- Hyperparameter sensitivity analysis (Random Search) for robustness
- Variations in data set for robustness
Noise einführen 
--> Wie reagiert Algorithmus auf Noise
Anzahl der Trainingsdaten 
--> Wieviele Samples bis Konvergenz?
Feature Selection
--> Welches Set optimiert bzgl. Runtime und Accuracy
Feature Complexity
--> Was passiert, wenn der Datensatz komplexer wird? (Veränderungen von Elementen aus Problemstellung wie z.B. Autos, Kunden, Restaurants)

Runtime