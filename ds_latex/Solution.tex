\chapter{Methodology}
This chapter presents the solution approach.
Section 4.1 motivates our problem. 
Section 4.2 gives and introduction to supervised learning and presents the algorithms considered in the comparison in detail.
Section 4.3 is about the different feature selection techniques applied in the computational study. 
Section 4.4 defines the process by which we evaluate the algorithms in order to assess the quality of each algorithm.

\section{Motivation}

- Why machine learning --> Why offline supervised learning --> Why Tree-Based ensembles and NNs
- Why bother comparing them


\section{Algorithms}

This section shortly introduces the framework of supervised learning to proceed with the detailed examination of how each algorithm included in our comparison works. This chapter requires basic knowledge in set theory, linear algebra, analysis and statistics.

Supervised learning models receive \textbf{training data} in form of a finite set $ S = \{(\textbf{x}_{2}, y_2), (\textbf{x}_{2}, y_2), \dots, (\textbf{x}_{n}, y_n)\}$ of N pairs from $ X \times Y $ as inputs based on which they aim to approximate a \textbf{hypothesis} $ h: X \to Y $  that maps the ground truth relationship between $ X $ and $ Y $ well in order to have a \textbf{model} that is able to make a prediction $ h(\textbf{x}) $ for any, but especially $ \textbf{x} \notin S $ accurately by means of $ h \in H $. All $ \textbf{x} \in X $ not contained in the training data $ S $ is called \textbf{test data}. 
In supervised learning, $ X $ is the \textbf{feature space} represented as a matrix of N \textbf{observations} with each of them being described by p \textbf{features}. $ Y $ is the \textbf{label space} that contains the corresponding \textbf{label} $ y \in Y $ to a observation $ \textbf{x} $ and is represented as a N-dimensional vector:   
\begin{equation*}
X = 
\begin{pmatrix}
\textbf{x}_{1} \\
\textbf{x}_{2} \\
\vdots \\
\textbf{x}_{n} \\
\end{pmatrix} 
=
\begin{pmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,p} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,p} \\
\vdots  & \vdots  & \ddots & \vdots \\
x_{n,1} & x_{n,2} & \cdots & x_{n,p} \\
\end{pmatrix}
,
Y = 
\begin{pmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{n} \\
\end{pmatrix}
\end{equation*}
The prediction accuracy of an hypothesis $ h $ is measured with an arbitrarily chosen \textbf{loss function} (or synonymously: \textit{cost function}) $ L : Y \times Y \to \mathbb{R}^{\geq 0}$. For a given pair $ (\textbf{x}_i, y_i) $, the loss function $ L(y_i, h(\textbf{x}_i)) $ represents the deviance of a predicted target $ h(\textbf{x}_i) $ from the ground truth target $ y_i $. 
% Done: io structure, loss function, hypothesis, training and test data
% Todo: Set loss function in context to hypothesis (je kleiner loss desto besser hypothese)  
Predictions can generally be made for either a \textbf{regression} or \textbf{classification} problem which differ in the nature of their target variable. While regression is used to predict continuous targets $ Y = \mathbb{R} $, classification predicts discrete $ Y $. The arrival time estimation problem is a regression task since we are estimating (continuous) arrival times.
Although various supervised learning models use different mathematical procedures to predict targets, all of them follow the principle of induction, meaning that general rules are inductively inferred from made observations, i.e. training data. This is also called \textbf{generalization}.  
In order for a model to generalize well, two phenomenons have to be avoided: \textbf{Underfitting} and \textbf{Overfitting}. Poor predictions on both the training and test data indicate that a model is underfitted, whereas an overfitted model is characterized by very good prediction accuracy on the training data, but poor accuracy on test data. Technically speaking, they occur when a model has either too few or too many free parameters. In supervised learning, this is known as the \textbf{bias-variance tradeoff}. A overfitted model is low in bias and high in variance, whereas the same goes vice versa for underfitted models. The key challenge therefore lies in discovering a model that is ideally low in bias and low in variance and thus has good prediction accuracy especially on test data.
 
\subsection{Linear Models}

\subsection{Tree-based ensembles}

As shown in the literature review, tree-based methods are popular in the field of arrival time estimation. 
The structure of regression trees allows classification of given samples in a greedy fashion. Regression trees are unidirectional, binary data structures consisting of branch and terminal nodes. Branch nodes partition samples according to a binary condition. Terminal nodes represent disjunct regions containing the samples based on former partitions made by the branch nodes.

Let M denote the amount of terminal nodes and $ R_m $ with $ m = 1, ..., M $ the m-th terminal node. 









The first step in GBDT is to initialize a model by taking the derivate of the loss function with a known target $ y_i $ and an unknown target prediction $ \gamma $ that is constant for all corresponding $ y_i $.
\begin{equation}
F_{0}(x) =  \argmin_{\gamma} \sum_{i=1}^n L(y_i,\gamma) \label{gbdt_step1}
\end{equation}
Given the initial model $ F_0(x) $, M regression trees can now be build sequentially as shown in the following. 
The first step computes pseudo-residuals $ r_{im} $ between the prediction value of the former learner for the i-th observation $ F_{m-1}(x) $ and the actual i-th target for the m-th tree $ y_i $by deriving the loss function w.r.t to $ F_{m-1}(x) $: 
\begin{equation}
	r_{im}\ = - \bigg[\dfrac{\delta L(y_i, F(x_i))}{\delta F(x_i)}\bigg]_{F(x) = F_{m-1}(x)}
\end{equation} 
for every i-th example.

In the second step, the algorithm fits a regression tree to every $ r_{im} $ and creates disjoint regions $ R_{jm} $ for $j = 1, ..., J_m$. 

In the third step, we compute: 
\begin{equation}
	\gamma_{jm} = \argmin_{\gamma} \sum_{x_i \in R_{ij}} L(y_i, F_{m-1}(x_i) + \gamma)
\end{equation}
for every terminal region j in the m-th tree. 
Given this, we now update the former weak learner with the new one:
\begin{equation}
	F_m(x) = F_{m-1}(x) + \alpha \sum_{j=1}^{J_m} \gamma_{m}I(x \in R_{jm})
\end{equation}
where $ \alpha $ is the learning rate, and $ I(\cdot) $ is the indicator function.

\subsection{Neural Networks}

\section{Feature Selection}

As shown, researchers used different feature selection methods. A majority of the presented papers crafted their features manually relying on their domain expertise, whereas others (e.g \cite{Siripanpornchana2016_AnnWithDbnFS} and \cite{Huang2018_GBDT}) used representation learning techniques.


- Raw Data 
- Manual feature selection
- Feature learning via deep autoencoder

\section{Evaluation} 
- Use MSE, MAE, MAPE etc. to derive infos about accuracy
- Hyperparameter sensitivity analysis (Random Search) for robustness
- Variations in data set for robustness
Noise einführen 
--> Wie reagiert Algorithmus auf Noise
Anzahl der Trainingsdaten 
--> Wieviele Samples bis Konvergenz?
Feature Selection
--> Welches Set optimiert bzgl. Runtime und Accuracy
Feature Complexity
--> Was passiert, wenn der Datensatz komplexer wird? (Veränderungen von Elementen aus Problemstellung wie z.B. Autos, Kunden, Restaurants)

Runtime