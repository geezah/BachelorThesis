\chapter{Methodology}
This chapter presents the solution approach.
Section 4.1 motivates our problem. 
Section 4.2 gives and introduction to supervised learning and presents the algorithms considered in the comparison in detail.
Section 4.3 is about the different feature selection techniques applied in the computational study. 
Section 4.4 defines the process by which we evaluate the algorithms in order to assess the quality of each algorithm.

\chapter{Motivation}

- Why machine learning --> Why offline supervised learning --> Why Tree-Based ensembles and NNs
- Why bother comparing them


\section{Algorithms}

This section gives a short introduction to the conceptual framework of supervised learning and then examines the algorithms included in our comparison. For further research, the interested reader is referred to \cite{Bishop} and \cite{SLFoundations}. This chapter requires basic knowledge in set theory, linear algebra and analysis.

Given is a finite set $ S = \{(\textbf{x}_{2}, y_2), (\textbf{x}_{2}, y_2), \dots, (\textbf{x}_{n}, y_n)\}$ of N pairs from $ X \times Y $ as inputs based on which supervised learning models aim to approximate a \textbf{hypothesis} $ h: X \to Y $  that fits the ground truth relationship between $ X $ and $ Y $ well in order to predict $ y_i $ for any $ x_i $ by means of $ h \in H $ accurately, with $ H $ being the \textbf{hypothesis space}. In supervised learning, $ X $ is called the \textbf{input space} consisting of N observations described by p (independent) \textbf{feature variables}, whereas $ Y $ represents the \textbf{output space} containing the corresponding target value $ y_i $ for any given $ x_i $:   
\begin{equation*}
X = 
\begin{pmatrix}
\textbf{x}_{1} \\
\textbf{x}_{2} \\
\vdots \\
\textbf{x}_{n} \\
\end{pmatrix} 
=
\begin{pmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,p} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,p} \\
\vdots  & \vdots  & \ddots & \vdots \\
x_{n,1} & x_{n,2} & \cdots & x_{n,p} \\
\end{pmatrix}
,
Y = 
\begin{pmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{n} \\
\end{pmatrix}
\end{equation*}
The accuracy of a prediction $ h(x_i) = \hat{y}_{i} $ for a given $ x_i $ is measured with an arbitrarily chosen \textbf{loss function} (or synonymously: \textit{cost function}) $ L : Y \times Y \to \mathbb{R}^{\geq 0}$. 
For a given pair $ (x_i, y_i) $, the loss function $ L(y_i, \hat{y}_i) $ represents the deviance of a predicted target $ \hat{y}_{i} $ from the ground truth target $ y_i $.


Predictions can generally be made for either a \textbf{regression} or \textbf{classification} problem which differ in the nature of their target variable. While regression is used to predict continuous targets $ Y = \mathbb{R} $, classification predicts discrete $ Y $. The arrival time estimation problem is a regression task since we are estimating (continuous) arrival times.
Although various supervised learning models use different mathematical procedures to predict targets, all of them follow the principle of induction, meaning that general rules are inductively inferred from labelled data. This is also called \textbf{generalization}.  
In order for a model to generalize the data properly, two things have to be avoided: \textbf{Underfitting} and \textbf{Overfitting}. Poor predictions on both the training and test data indicate a underfitted model, whereas a overfitted model does very well on training data, but poorly on test data. In supervised learning, this problem is known as the \textbf{bias-variance tradeoff}. A overfitted model is low in bias and high in variance, whereas the same goes vice versa for underfitted models. The key challenge therefore lies in discovering a model that is ideally low in bias and low in variance and thus has good prediction accuracy especially on test data. 

\subsection{Linear Models}

\subsection{Tree-based ensembles}

As shown in the literature review, tree-based methods are popular in the field of arrival time estimation. 

The structure of regression trees allows  of given samples in a greedy fashion. Regression trees are unidirectional, binary data structures consisting of branch and terminal nodes.

Let M denote the amount of terminal nodes and $ R_m $ with $ m = 1, ..., M $ the m-th terminal node. 








 











The first step in GBDT is to initialize a model by taking the derivate of the loss function with a known target $ y_i $ and an unknown target prediction $ \gamma $ that is constant for all corresponding $ y_i $.
\begin{equation}
F_{0}(x) =  \argmin_{\gamma} \sum_{i=1}^n L(y_i,\gamma) \label{gbdt_step1}
\end{equation}
Given the initial model $ F_0(x) $, M regression trees can now be build sequentially as shown in the following. 
The first step computes pseudo-residuals $ r_{im} $ between the prediction value of the former learner for the i-th observation $ F_{m-1}(x) $ and the actual i-th target for the m-th tree $ y_i $by deriving the loss function w.r.t to $ F_{m-1}(x) $: 
\begin{equation}
	r_{im}\ = - \bigg[\dfrac{\delta L(y_i, F(x_i))}{\delta F(x_i)}\bigg]_{F(x) = F_{m-1}(x)}
\end{equation} 
for every i-th example.

In the second step, the algorithm fits a regression tree to every $ r_{im} $ and creates disjoint regions $ R_{jm} $ for $j = 1, ..., J_m$. 

In the third step, we compute: 
\begin{equation}
	\gamma_{jm} = \argmin_{\gamma} \sum_{x_i \in R_{ij}} L(y_i, F_{m-1}(x_i) + \gamma)
\end{equation}
for every terminal region j in the m-th tree. 
Given this, we now update the former weak learner with the new one:
\begin{equation}
	F_m(x) = F_{m-1}(x) + \alpha \sum_{j=1}^{J_m} \gamma_{m}I(x \in R_{jm})
\end{equation}
where $ \alpha $ is the learning rate, and $ I(x \in R_{jm}) $ is the indicator function.

\subsection{Neural Networks}

\section{Feature Selection}

As shown, researchers used different feature selection methods. A majority of the presented papers crafted their features manually relying on their domain expertise, whereas others (e.g \cite{Siripanpornchana2016_AnnWithDbnFS} and \cite{Huang2018_GBDT}) used representation learning techniques.


- Raw Data 
- Manual feature selection
- Feature learning via deep autoencoder

\section{Evaluation} 
- Use MSE, MAE, MAPE etc. to derive infos about accuracy
- Hyperparameter sensitivity analysis (Random Search) for robustness
- Variations in data set for robustness
Noise einführen 
--> Wie reagiert Algorithmus auf Noise
Anzahl der Trainingsdaten 
--> Wieviele Samples bis Konvergenz?
Feature Selection
--> Welches Set optimiert bzgl. Runtime und Accuracy
Feature Complexity
--> Was passiert, wenn der Datensatz komplexer wird? (Veränderungen von Elementen aus Problemstellung wie z.B. Autos, Kunden, Restaurants)

Runtime